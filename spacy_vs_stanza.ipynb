{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pierr\\.conda\\envs\\data-td\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.stanza_spacy_compare import *\n",
    "from nltk.probability import FreqDist\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import stanza\n",
    "import spacy\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path used to store csv files requested for the project.\n",
    "CSV_TEXT_PATH = 'data/part2/texts.csv'\n",
    "CSV_SHARED_SENTENCE_PATH = 'data/part2/shared_sentences.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection from scratch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of the notebook loading text files using the requested function (create_textset).\n",
    "\n",
    "It also apply spacy and stanza on each text.\n",
    "\n",
    "We advise you to stay with a small N value because stanza processing is very slow.\n",
    "\n",
    "Further in the notebook there is a section wich load precomputed text from \"sm\" sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which folder to use to load text from files.\n",
    "TEXT_FOLDER_PATH = 'data/sm/pages'\n",
    "# Number of file/text to load.\n",
    "N = 10\n",
    "# Name of spacy model to use (https://spacy.io/models)\n",
    "SPACY_MODEL_NAME = 'en_core_web_sm'\n",
    "# Name of stanza model to use (https://stanfordnlp.github.io/stanza/available_models.html)\n",
    "STANZA_MODEL_NAME = 'en' \n",
    "# As stanza model is really slow we reduce the number of component.\n",
    "STANZA_MODEL_PROCESSORS = 'tokenize,pos,lemma,depparse'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load spacy and stanza pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spacy.load(SPACY_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 21:48:21 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json: 216kB [00:00, 54.0MB/s]                    \n",
      "2023-05-16 21:48:22 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| pos       | combined |\n",
      "| lemma     | combined |\n",
      "| depparse  | combined |\n",
      "========================\n",
      "\n",
      "2023-05-16 21:48:22 INFO: Using device: cpu\n",
      "2023-05-16 21:48:22 INFO: Loading: tokenize\n",
      "2023-05-16 21:48:22 INFO: Loading: pos\n",
      "2023-05-16 21:48:22 INFO: Loading: lemma\n",
      "2023-05-16 21:48:22 INFO: Loading: depparse\n",
      "2023-05-16 21:48:23 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "st = stanza.Pipeline(STANZA_MODEL_NAME, processors=STANZA_MODEL_PROCESSORS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arthur Hamilton Gibbs (9 March 1888 – 24 May 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Akkamappettai Paramasivan Nagarajan (24 Februa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aasif Sheikh (Nepali: आसिफ शेख; born 22 Januar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adam Morris (also known as Wayne Morris) is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adriana Farmiga ( far-MEE-gə; born July 17, 19...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Arthur Hamilton Gibbs (9 March 1888 – 24 May 1...\n",
       "1  Akkamappettai Paramasivan Nagarajan (24 Februa...\n",
       "2  Aasif Sheikh (Nepali: आसिफ शेख; born 22 Januar...\n",
       "3  Adam Morris (also known as Wayne Morris) is a ...\n",
       "4  Adriana Farmiga ( far-MEE-gə; born July 17, 19..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use create_textset to create a dataframe with text from files\n",
    "text_df = pd.DataFrame(create_textset(TEXT_FOLDER_PATH, N), columns=['text'])\n",
    "text_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  7.47it/s]\n"
     ]
    }
   ],
   "source": [
    "text_df['spacy'] = text_df['text'].progress_apply(sp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:29<00:00,  8.92s/it]\n"
     ]
    }
   ],
   "source": [
    "text_df['stanza'] = text_df['text'].progress_apply(st)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save text DataFrame in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spacy</th>\n",
       "      <th>stanza</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arthur Hamilton Gibbs (9 March 1888 – 24 May 1...</td>\n",
       "      <td>Arthur Hamilton Gibbs (9 March 1888 – 24 May 1...</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Akkamappettai Paramasivan Nagarajan (24 Februa...</td>\n",
       "      <td>Akkamappettai Paramasivan Nagarajan (24 Februa...</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aasif Sheikh (Nepali: आसिफ शेख; born 22 Januar...</td>\n",
       "      <td>Aasif Sheikh (Nepali: आसिफ शेख; born 22 Januar...</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adam Morris (also known as Wayne Morris) is a ...</td>\n",
       "      <td>Adam Morris (also known as Wayne Morris) is a ...</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adriana Farmiga ( far-MEE-gə; born July 17, 19...</td>\n",
       "      <td>Adriana Farmiga ( far-MEE-gə; born July 17, 19...</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Arthur Hamilton Gibbs (9 March 1888 – 24 May 1...   \n",
       "1  Akkamappettai Paramasivan Nagarajan (24 Februa...   \n",
       "2  Aasif Sheikh (Nepali: आसिफ शेख; born 22 Januar...   \n",
       "3  Adam Morris (also known as Wayne Morris) is a ...   \n",
       "4  Adriana Farmiga ( far-MEE-gə; born July 17, 19...   \n",
       "\n",
       "                                               spacy  \\\n",
       "0  Arthur Hamilton Gibbs (9 March 1888 – 24 May 1...   \n",
       "1  Akkamappettai Paramasivan Nagarajan (24 Februa...   \n",
       "2  Aasif Sheikh (Nepali: आसिफ शेख; born 22 Januar...   \n",
       "3  Adam Morris (also known as Wayne Morris) is a ...   \n",
       "4  Adriana Farmiga ( far-MEE-gə; born July 17, 19...   \n",
       "\n",
       "                                              stanza  \n",
       "0  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...  \n",
       "1  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...  \n",
       "2  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...  \n",
       "3  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...  \n",
       "4  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.to_csv(CSV_TEXT_PATH, index=False)\n",
    "pd.read_csv(CSV_TEXT_PATH).head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection from sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which sample to loads.\n",
    "SAMPLE_NAME = 'sm'\n",
    "# Which type of text to use. \"abstract\" or \"page\"\n",
    "TEXT_KEY = 'page'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jason Edward Feddy (born 22 February 1966) is ...</td>\n",
       "      <td>(Jason, Edward, Feddy, (, born, 22, February, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Robert Scarlett (born 14 January 1979) is a Ja...</td>\n",
       "      <td>(Robert, Scarlett, (, born, 14, January, 1979,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bahram Sadeghi (Persian: بهرام صادقی, romanize...</td>\n",
       "      <td>(Bahram, Sadeghi, (, Persian, :, بهرام, صادقی,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nadav Asher Eyal  (Hebrew: נדב אשר איל; born M...</td>\n",
       "      <td>(Nadav, Asher, Eyal,  , (, Hebrew, :, נדב, אשר...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>David Nthubu Koloane (5 June 1938 – 30 June 20...</td>\n",
       "      <td>(David, Nthubu, Koloane, (, 5, June, 1938, –, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Jason Edward Feddy (born 22 February 1966) is ...   \n",
       "1  Robert Scarlett (born 14 January 1979) is a Ja...   \n",
       "2  Bahram Sadeghi (Persian: بهرام صادقی, romanize...   \n",
       "3  Nadav Asher Eyal  (Hebrew: נדב אשר איל; born M...   \n",
       "4  David Nthubu Koloane (5 June 1938 – 30 June 20...   \n",
       "\n",
       "                                               spacy  \n",
       "0  (Jason, Edward, Feddy, (, born, 22, February, ...  \n",
       "1  (Robert, Scarlett, (, born, 14, January, 1979,...  \n",
       "2  (Bahram, Sadeghi, (, Persian, :, بهرام, صادقی,...  \n",
       "3  (Nadav, Asher, Eyal,  , (, Hebrew, :, נדב, אשר...  \n",
       "4  (David, Nthubu, Koloane, (, 5, June, 1938, –, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use create_textset to create a dataframe with text from files\n",
    "text_df = pd.DataFrame(\n",
    "    [(doc[TEXT_KEY].text, doc[TEXT_KEY]) for doc in pickle.loads(Path(f'data/{SAMPLE_NAME}/spacy.pkl').read_bytes())], \n",
    "    columns=['text', 'spacy']\n",
    ")\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df['stanza'] = [doc[TEXT_KEY] for doc in pickle.loads(Path(f'data/{SAMPLE_NAME}/stanza.pkl').read_bytes())]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence segmentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute len of sentences for both library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 25001.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# Apply compute_sent_len and store results in text_df new columns\n",
    "text_df[['sp_sent_len', 'st_sent_len']] = text_df.progress_apply(lambda x: compute_sent_len(x[1], x[2]), axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sp_sent_len</th>\n",
       "      <th>st_sent_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>27.694000</td>\n",
       "      <td>29.993000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>40.831747</td>\n",
       "      <td>42.627504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>591.000000</td>\n",
       "      <td>592.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sp_sent_len  st_sent_len\n",
       "count  1000.000000  1000.000000\n",
       "mean     27.694000    29.993000\n",
       "std      40.831747    42.627504\n",
       "min       1.000000     1.000000\n",
       "25%       8.000000     9.000000\n",
       "50%      16.000000    19.000000\n",
       "75%      32.000000    34.000000\n",
       "max     591.000000   592.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute shared sentences for both library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2147.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shared_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"By the time Jason Feddy starts, [its] not jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A review by the New York Times described Feddy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An affable sort of a guy with a soft, reedy sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The band opened to rave reviews: \"We included ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>His mother was (and still is) an active member...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     shared_sentence\n",
       "0  \"By the time Jason Feddy starts, [its] not jus...\n",
       "1  A review by the New York Times described Feddy...\n",
       "2  An affable sort of a guy with a soft, reedy sp...\n",
       "3  The band opened to rave reviews: \"We included ...\n",
       "4  His mother was (and still is) an active member..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply compute_shared_sentences, reduce results and store it in a Dataframe\n",
    "shared_sentences = text_df.progress_apply(lambda x: compute_shared_sentences(x[1], x[2]), axis=1)\n",
    "shared_sentence_df = pd.DataFrame(reduce(lambda a, b: a + b, shared_sentences, []), columns=['shared_sentence'])\n",
    "shared_sentence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sp_sent_len</th>\n",
       "      <th>st_sent_len</th>\n",
       "      <th>shared_sentences_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>27.694000</td>\n",
       "      <td>29.993000</td>\n",
       "      <td>16.068000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>40.831747</td>\n",
       "      <td>42.627504</td>\n",
       "      <td>25.736389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>591.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>352.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sp_sent_len  st_sent_len  shared_sentences_len\n",
       "count  1000.000000  1000.000000           1000.000000\n",
       "mean     27.694000    29.993000             16.068000\n",
       "std      40.831747    42.627504             25.736389\n",
       "min       1.000000     1.000000              0.000000\n",
       "25%       8.000000     9.000000              3.000000\n",
       "50%      16.000000    19.000000              9.000000\n",
       "75%      32.000000    34.000000             20.000000\n",
       "max     591.000000   592.000000            352.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many document doesn't share sentence\n",
    "text_df['shared_sentences_len'] = pd.Series(shared_sentences).apply(len)\n",
    "text_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spacy</th>\n",
       "      <th>stanza</th>\n",
       "      <th>sp_sent_len</th>\n",
       "      <th>st_sent_len</th>\n",
       "      <th>shared_sentences_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Éric Lada (born October 14, 1965 in Chartres) ...</td>\n",
       "      <td>(Éric, Lada, (, born, October, 14, ,, 1965, in...</td>\n",
       "      <td>[\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "55  Éric Lada (born October 14, 1965 in Chartres) ...   \n",
       "\n",
       "                                                spacy  \\\n",
       "55  (Éric, Lada, (, born, October, 14, ,, 1965, in...   \n",
       "\n",
       "                                               stanza  sp_sent_len  \\\n",
       "55  [\\n  [\\n    {\\n      \"id\": 1,\\n      \"text\": \"...            1   \n",
       "\n",
       "    st_sent_len  shared_sentences_len  \n",
       "55            1                     1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df[text_df['shared_sentences_len'] == text_df['sp_sent_len']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shared_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"By the time Jason Feddy starts, [its] not jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A review by the New York Times described Feddy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An affable sort of a guy with a soft, reedy sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The band opened to rave reviews: \"We included ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>His mother was (and still is) an active member...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     shared_sentence\n",
       "0  \"By the time Jason Feddy starts, [its] not jus...\n",
       "1  A review by the New York Times described Feddy...\n",
       "2  An affable sort of a guy with a soft, reedy sp...\n",
       "3  The band opened to rave reviews: \"We included ...\n",
       "4  His mother was (and still is) an active member..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared_sentence_df.to_csv(CSV_SHARED_SENTENCE_PATH, index=False)\n",
    "pd.read_csv(CSV_SHARED_SENTENCE_PATH).head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary recognised by each library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Fluoreszenz',\n",
       " 'Invader',\n",
       " '\"Gaines',\n",
       " 'Dislocations',\n",
       " '156795066',\n",
       " 'Korus',\n",
       " 'Elder',\n",
       " 'Henryk',\n",
       " 'Volume',\n",
       " 'Prosecutors',\n",
       " 'Rajaye',\n",
       " 'Jerome',\n",
       " 'instant',\n",
       " '3.89',\n",
       " 'Blacks',\n",
       " '1994,has',\n",
       " 'Braque',\n",
       " 'invocations',\n",
       " 'abstraits',\n",
       " 'Madeira',\n",
       " 'Shadowmaker',\n",
       " 'TheReggaeboyz',\n",
       " 'Lagow',\n",
       " 'Stray',\n",
       " 'Kamwada']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_vocab = compute_spacy_vocabulary(text_df['spacy'])\n",
    "# Increase or remove slice to display more tokens\n",
    "print(len(spacy_vocab))\n",
    "list(spacy_vocab)[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Fluoreszenz',\n",
       " 'Invader',\n",
       " 'Dislocations',\n",
       " '156795066',\n",
       " '[...]',\n",
       " 'Korus',\n",
       " 'Elder',\n",
       " 'Henryk',\n",
       " 'Volume',\n",
       " 'Prosecutors',\n",
       " 'Rajaye',\n",
       " 'Jerome',\n",
       " 'instant',\n",
       " 'treasury',\n",
       " '3.89',\n",
       " 'Blacks',\n",
       " 'Braque',\n",
       " 'invocations',\n",
       " 'abstraits',\n",
       " 'Madeira',\n",
       " 'Shadowmaker',\n",
       " 'TheReggaeboyz',\n",
       " 'Lagow',\n",
       " 'Stray',\n",
       " 'Kamwada']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Increase or remove slice to display more tokens \n",
    "stanza_vocab = compute_stanza_vocabulary(text_df['stanza'])\n",
    "print(len(stanza_vocab))\n",
    "list(stanza_vocab)[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Fluoreszenz',\n",
       " 'Invader',\n",
       " 'Dislocations',\n",
       " '156795066',\n",
       " 'Korus',\n",
       " 'Elder',\n",
       " 'Henryk',\n",
       " 'Volume',\n",
       " 'Prosecutors',\n",
       " 'Rajaye',\n",
       " 'Jerome',\n",
       " 'instant',\n",
       " '3.89',\n",
       " 'Blacks',\n",
       " 'Braque',\n",
       " 'invocations',\n",
       " 'abstraits',\n",
       " 'Madeira',\n",
       " 'Shadowmaker',\n",
       " 'TheReggaeboyz',\n",
       " 'Lagow',\n",
       " 'Stray',\n",
       " 'Kamwada',\n",
       " '20.25',\n",
       " 'concurring']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared_vocab = spacy_vocab & stanza_vocab\n",
    "print(len(shared_vocab))\n",
    "# Increase or remove slice to display more tokens\n",
    "list(shared_vocab)[:25]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The set of tokens that is specific to spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2⁄3',\n",
       " '\"Gaines',\n",
       " 'G-20',\n",
       " '30.Law',\n",
       " '\"During',\n",
       " '42–35',\n",
       " '1994,has',\n",
       " '1902.As',\n",
       " 'year—40,000',\n",
       " '65–51',\n",
       " '1956–1994',\n",
       " '1814–1867',\n",
       " 'ordinator',\n",
       " '47.Palaszewski',\n",
       " '19–7',\n",
       " 'for-3',\n",
       " 'CLOUD',\n",
       " '\\n \\n\\n\\n',\n",
       " '7011',\n",
       " '1959Silver',\n",
       " 'Import',\n",
       " 'Opta',\n",
       " '67–67',\n",
       " '4230',\n",
       " '1925–1940']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_only_vocab = spacy_vocab - stanza_vocab\n",
    "print(len(spacy_only_vocab))\n",
    "# Increase or remove slice to display more tokens\n",
    "list(spacy_only_vocab)[:25]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The set of tokens that is specific to stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2⁄3',\n",
       " '\"Gaines',\n",
       " 'G-20',\n",
       " '30.Law',\n",
       " '\"During',\n",
       " '42–35',\n",
       " '1994,has',\n",
       " '1902.As',\n",
       " 'year—40,000',\n",
       " '65–51',\n",
       " '1956–1994',\n",
       " '1814–1867',\n",
       " 'ordinator',\n",
       " '47.Palaszewski',\n",
       " '19–7',\n",
       " 'for-3',\n",
       " 'CLOUD',\n",
       " '\\n \\n\\n\\n',\n",
       " '7011',\n",
       " '1959Silver',\n",
       " 'Import',\n",
       " 'Opta',\n",
       " '67–67',\n",
       " '4230',\n",
       " '1925–1940']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stanza_only_vocab = stanza_vocab - spacy_vocab\n",
    "print(len(stanza_only_vocab))\n",
    "# Increase or remove slice to display more tokens\n",
    "list(spacy_only_vocab)[:25]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The set of shared token occurrences without sentence segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 3391),\n",
       " ('the', 2596),\n",
       " ('.', 2209),\n",
       " ('in', 1397),\n",
       " ('of', 1396),\n",
       " ('(', 1328),\n",
       " ('and', 1257),\n",
       " (')', 1254),\n",
       " ('a', 1219),\n",
       " ('is', 762),\n",
       " ('was', 734),\n",
       " ('born', 606),\n",
       " ('for', 506),\n",
       " ('to', 466),\n",
       " ('as', 466),\n",
       " ('He', 460),\n",
       " ('-', 404),\n",
       " ('an', 388),\n",
       " ('\"', 372),\n",
       " ('–', 327),\n",
       " ('who', 272),\n",
       " ('his', 266),\n",
       " ('he', 231),\n",
       " (':', 230),\n",
       " ('from', 217)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared_token_by_docs = compute_token_by_doc(text_df['spacy'], text_df['stanza'])\n",
    "# Increase most_common argument to display more result\n",
    "FreqDist([t.text for t, _ in shared_token_by_docs]).most_common(25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The set of shared token occurrences with sentence segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 11251),\n",
       " ('the', 10320),\n",
       " ('.', 8373),\n",
       " ('in', 5685),\n",
       " ('of', 5590),\n",
       " ('and', 5034),\n",
       " ('a', 4028),\n",
       " ('was', 3152),\n",
       " ('to', 3145),\n",
       " ('He', 2445),\n",
       " ('he', 2088),\n",
       " ('for', 1942),\n",
       " ('(', 1887),\n",
       " ('his', 1767),\n",
       " (')', 1740),\n",
       " ('as', 1621),\n",
       " ('-', 1426),\n",
       " ('at', 1281),\n",
       " ('In', 1267),\n",
       " ('on', 1185),\n",
       " ('is', 1158),\n",
       " ('with', 1153),\n",
       " ('\"', 1107),\n",
       " (\"'s\", 992),\n",
       " ('from', 962)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared_token_by_sentences = compute_token_by_sentence(text_df['spacy'], text_df['stanza'])\n",
    "# Increase most_common argument to display more result\n",
    "FreqDist([t.text for t, _ in shared_token_by_sentences]).most_common(25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pos_count, valid_pos_ratio, spacy_pos, stanza_pos = compute_valid_pos(shared_token_by_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192555.0, 95.37)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of equivalent pos, ratio of equivalent pos\n",
    "valid_pos_count, valid_pos_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJ': 91.48,\n",
       " 'ADP': 0.08,\n",
       " 'ADV': 0.55,\n",
       " 'AUX': 0.0,\n",
       " 'CCONJ': 0.0,\n",
       " 'DET': 0.01,\n",
       " 'INTJ': 0.01,\n",
       " 'NOUN': 3.81,\n",
       " 'NUM': 0.02,\n",
       " 'PART': 0.0,\n",
       " 'PRON': 0.03,\n",
       " 'PROPN': 1.57,\n",
       " 'PUNCT': 0.24,\n",
       " 'SCONJ': 0.0,\n",
       " 'SYM': 0.0,\n",
       " 'VERB': 2.03,\n",
       " 'X': 0.16}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stanza pos frequancy for spacy ADJ\n",
    "spacy_pos['ADJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADJ': 72.55,\n",
       " 'ADP': 0.06,\n",
       " 'ADV': 0.73,\n",
       " 'AUX': 0.0,\n",
       " 'CCONJ': 0.0,\n",
       " 'DET': 0.0,\n",
       " 'INTJ': 0.0,\n",
       " 'NOUN': 1.55,\n",
       " 'NUM': 0.03,\n",
       " 'PART': 0.0,\n",
       " 'PRON': 0.0,\n",
       " 'PROPN': 24.33,\n",
       " 'PUNCT': 0.0,\n",
       " 'SCONJ': 0.0,\n",
       " 'SYM': 0.0,\n",
       " 'VERB': 0.75,\n",
       " 'X': 0.02}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spacy pos frequancy for stanza ADJ\n",
    "stanza_pos['ADJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADJ 91.48 72.55\n",
      "ADP 96.87 98.73\n",
      "ADV 94.31 82.2\n",
      "AUX 99.07 99.85\n",
      "CCONJ 99.78 99.37\n",
      "DET 99.78 99.09\n",
      "INTJ 23.53 30.77\n",
      "NOUN 95.74 95.15\n",
      "NUM 99.49 98.47\n",
      "PART 97.17 98.44\n",
      "PRON 98.52 99.52\n",
      "PROPN 89.14 97.22\n",
      "PUNCT 98.73 99.51\n",
      "SCONJ 50.13 53.48\n",
      "SYM 90.48 26.55\n",
      "VERB 97.06 96.44\n",
      "X 27.87 7.19\n"
     ]
    }
   ],
   "source": [
    "# Display same tag frequency for each tags\n",
    "# Tag, Spacy, Stanza\n",
    "for tag in POS_TAGS:\n",
    "    print(tag, spacy_pos[tag][tag], stanza_pos[tag][tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADJ': 1.64, 'ADP': 0.82, 'ADV': 0.82, 'AUX': 0.0, 'CCONJ': 0.0, 'DET': 0.0, 'INTJ': 0.0, 'NOUN': 4.1, 'NUM': 1.64, 'PART': 0.0, 'PRON': 0.0, 'PROPN': 35.25, 'PUNCT': 27.87, 'SCONJ': 0.0, 'SYM': 0.0, 'VERB': 0.0, 'X': 27.87}\n",
      "{'ADJ': 3.17, 'ADP': 1.27, 'ADV': 1.06, 'AUX': 0.0, 'CCONJ': 0.0, 'DET': 0.63, 'INTJ': 0.21, 'NOUN': 21.99, 'NUM': 0.0, 'PART': 0.0, 'PRON': 0.42, 'PROPN': 59.41, 'PUNCT': 0.85, 'SCONJ': 0.0, 'SYM': 0.0, 'VERB': 3.81, 'X': 7.19}\n"
     ]
    }
   ],
   "source": [
    "# Go deeper into X tag\n",
    "print(spacy_pos['X'])\n",
    "print(stanza_pos['X'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-td",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
